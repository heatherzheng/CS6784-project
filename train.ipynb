{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "505d84e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mchaowan\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import logging\n",
    "import math\n",
    "import os\n",
    "import warnings\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "import wandb\n",
    "from transformers import (\n",
    "    MODEL_WITH_LM_HEAD_MAPPING,\n",
    "    AutoConfig,\n",
    "    AutoModelWithLMHead,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    LineByLineTextDataset,\n",
    "    TextDataset,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    set_seed,\n",
    ")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "wandb.login()\n",
    "\n",
    "start = \"<|startoftext|>\"\n",
    "sep = \"<|sep|>\"\n",
    "\n",
    "\n",
    "def dict2obj(d):\n",
    "    \"\"\"Convert a dictionary to a class\"\"\"\n",
    "    if isinstance(d, list):\n",
    "        d = [dict2obj(x) for x in d]\n",
    "    if not isinstance(d, dict):\n",
    "        return d\n",
    "\n",
    "    class Class:\n",
    "        pass\n",
    "\n",
    "    obj = Class()\n",
    "    for k in d:\n",
    "        obj.__dict__[k] = dict2obj(d[k])\n",
    "    return obj\n",
    "\n",
    "\n",
    "def get_dataset(args, tokenizer, evaluate=False):\n",
    "    file_path = args.eval_data_file if evaluate else args.train_data_file\n",
    "    if args.line_by_line:\n",
    "        return LineByLineTextDataset(\n",
    "            tokenizer=tokenizer, file_path=file_path, block_size=args.block_size\n",
    "        )\n",
    "    else:\n",
    "        return TextDataset(\n",
    "            tokenizer=tokenizer,\n",
    "            file_path=file_path,\n",
    "            block_size=args.block_size,\n",
    "            overwrite_cache=args.overwrite_cache,\n",
    "        )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fae448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a smaller dataset for training and validation\n",
    "count=0\n",
    "path_full = \"hep_full_dataset/train_ml_full.txt\"\n",
    "path_part = \"hep_full_dataset/train_ml_50000.txt\"\n",
    "with open(path_full,\"r\") as full:   \n",
    "    with open(path_part,\"w+\") as part:\n",
    "        lines = full.readlines() \n",
    "        for line in lines:\n",
    "            if count<50000:\n",
    "                count+=1\n",
    "                part.write(f\"{line}\\n\")\n",
    "    part.close()\n",
    "full.close()\n",
    "\n",
    "print(f\"{count} training points created!\")\n",
    "\n",
    "# create a smaller dataset for training and validation\n",
    "count=0\n",
    "path_full = \"hep_full_dataset/valid_hep_full.txt\"\n",
    "path_part = \"hep_full_dataset/valid_hep_2000.txt\"\n",
    "with open(path_full,\"r\") as full:   \n",
    "    with open(path_part,\"w+\") as part:\n",
    "        lines = full.readlines() \n",
    "        for line in lines:\n",
    "            if count<2000:\n",
    "                count+=1\n",
    "                part.write(f\"{line}\\n\")\n",
    "    part.close()\n",
    "full.close()\n",
    "\n",
    "print(f\"{count} validation points created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0886b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8be0ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model arguments\n",
    "model_args = collections.defaultdict(\n",
    "    config_name=\"gpt2\",\n",
    "    model_name_or_path=\"gpt2\",\n",
    "    model_type=\"gpt2\",\n",
    "    tokenizer_name=\"gpt2\",\n",
    "    cache_dir=None,\n",
    ")\n",
    "# Data arguments\n",
    "data_args = collections.defaultdict(\n",
    "    train_data_file=\"ml_full_dataset/train_ml_full.txt\",\n",
    "    eval_data_file=\"ml_full_dataset/valid_ml_full.txt\",\n",
    "    line_by_line=True,\n",
    "    mlm=False,\n",
    "    mlm_probability=0.15,\n",
    "    block_size=512,\n",
    "    overwrite_cache=False,\n",
    ")\n",
    "\n",
    "# Convert dict to objects\n",
    "model_args = dict2obj(model_args)\n",
    "data_args = dict2obj(data_args)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f135bbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4a535d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c013d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded\n",
      "special tokens added\n"
     ]
    }
   ],
   "source": [
    "# Load tokenizer and model\n",
    "config = AutoConfig.from_pretrained(\n",
    "    model_args.model_name_or_path, cache_dir=model_args.cache_dir\n",
    ")\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_args.model_name_or_path, cache_dir=model_args.cache_dir\n",
    ")\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "    \n",
    "tokenizer.pad_token = \"[PAD]\"\n",
    "    \n",
    "    \n",
    "model = AutoModelWithLMHead.from_pretrained(\n",
    "    model_args.model_name_or_path,\n",
    "    from_tf=bool(\".ckpt\" in model_args.model_name_or_path),\n",
    "    config=config,\n",
    "    cache_dir=model_args.cache_dir,\n",
    ")\n",
    "\n",
    "print(\"model loaded\")\n",
    "\n",
    "# Add special tokens\n",
    "tokenizer.add_special_tokens({\"sep_token\": sep})\n",
    "tokenizer.add_special_tokens({\"bos_token\": start})\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    print(\"no pad token\")\n",
    "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "\n",
    "print(\"special tokens added\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77f45c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging\n",
    "logger = logging.getLogger(__name__)\n",
    "# Model classes\n",
    "MODEL_CONFIG_CLASSES = list(MODEL_WITH_LM_HEAD_MAPPING.keys())\n",
    "MODEL_TYPES = tuple(conf.model_type for conf in MODEL_CONFIG_CLASSES)\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"model_ml_full_1/\",\n",
    "    overwrite_output_dir=True,\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    do_predict=False,\n",
    "#    evaluate_during_training=True,\n",
    "    per_gpu_train_batch_size=4,\n",
    "    per_gpu_eval_batch_size=4,\n",
    "    gradient_accumulation_steps=1,\n",
    "    learning_rate=1e-5,\n",
    "    weight_decay=0.0,\n",
    "    adam_epsilon=1e-08,\n",
    "    max_grad_norm=1.0,\n",
    "    num_train_epochs=4.0,\n",
    "    max_steps=-1,\n",
    "    warmup_steps=0,\n",
    "    logging_dir=None,\n",
    "    logging_first_step=False,\n",
    "    logging_steps=1000,\n",
    "    save_steps=10000,\n",
    "    save_total_limit=100000,\n",
    "    no_cuda=False,\n",
    "    seed=123,\n",
    "    fp16=False,\n",
    "    fp16_opt_level=\"O1\",\n",
    "    local_rank=-1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "837b48fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set loaded\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "train_dataset = (\n",
    "    get_dataset(data_args, tokenizer=tokenizer) if training_args.do_train else None\n",
    ")\n",
    "\n",
    "print(\"train set loaded\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22757687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval set loaded\n"
     ]
    }
   ],
   "source": [
    "eval_dataset = (\n",
    "    get_dataset(data_args, tokenizer=tokenizer, evaluate=True)\n",
    "    if training_args.do_eval\n",
    "    else None\n",
    ")\n",
    "\n",
    "print(\"eval set loaded\")\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, mlm=data_args.mlm, mlm_probability=data_args.mlm_probability,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "447d6de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/28/2022 13:27:14 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 2, distributed training: False, 16-bits training: False\n",
      "03/28/2022 13:27:14 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(\n",
      "_n_gpu=2,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=True,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=IntervalStrategy.NO,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_strategy=HubStrategy.EVERY_SAVE,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=1e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=-1,\n",
      "log_level_replica=-1,\n",
      "log_on_each_node=True,\n",
      "logging_dir=model_ml_full_1/runs/Mar28_13-26-09_tripods-compute-01.cs.cornell.edu,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=1000,\n",
      "logging_strategy=IntervalStrategy.STEPS,\n",
      "lr_scheduler_type=SchedulerType.LINEAR,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=4.0,\n",
      "optim=OptimizerNames.ADAMW_HF,\n",
      "output_dir=model_ml_full_1/,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=8,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "remove_unused_columns=True,\n",
      "report_to=['wandb'],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=model_ml_full_1/,\n",
      "save_on_each_node=False,\n",
      "save_steps=10000,\n",
      "save_strategy=IntervalStrategy.STEPS,\n",
      "save_total_limit=100000,\n",
      "seed=123,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "tf32=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_legacy_prediction_loop=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialized trainer\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "#    prediction_loss_only=True,\n",
    ")\n",
    "\n",
    "print(\"initialized trainer\")\n",
    "\n",
    "# Logging\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    level=logging.INFO if training_args.local_rank in [-1, 0] else logging.WARN,\n",
    ")\n",
    "logger.warning(\n",
    "    \"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\",\n",
    "    training_args.local_rank,\n",
    "    training_args.device,\n",
    "    training_args.n_gpu,\n",
    "    bool(training_args.local_rank != -1),\n",
    "    training_args.fp16,\n",
    ")\n",
    "logger.info(\"Training/evaluation parameters %s\", training_args)\n",
    "\n",
    "# Seed\n",
    "set_seed(training_args.seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bff37ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model path defined\n"
     ]
    }
   ],
   "source": [
    "# Define model path\n",
    "model_path = (\n",
    "    model_args.model_name_or_path\n",
    "    if model_args.model_name_or_path is not None\n",
    "    and os.path.isdir(model_args.model_name_or_path)\n",
    "    else None\n",
    ")\n",
    "\n",
    "print(\"model path defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45af65af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n",
      "Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n",
      "***** Running training *****\n",
      "  Num examples = 182764\n",
      "  Num Epochs = 4\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 91384\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n",
      "Using deprecated `--per_gpu_eval_batch_size` argument which will be removed in a future version. Using `--per_device_eval_batch_size` is preferred.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start Training\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/chaowan/huggingface/runs/3fyvb6eu\" target=\"_blank\">model_ml_full_1/</a></strong> to <a href=\"https://wandb.ai/chaowan/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='465' max='91384' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  465/91384 04:15 < 13:56:00, 1.81 it/s, Epoch 0.02/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"start Training\")\n",
    "# Train the model\n",
    "start = timer()\n",
    "train_results = trainer.train(model_path=model_path)\n",
    "end = timer()\n",
    "print(\"Training completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418b0e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model()\n",
    "print(\"model saved\")\n",
    "\n",
    "\n",
    "if trainer.is_world_process_zero():\n",
    "    tokenizer.save_pretrained(training_args.output_dir)\n",
    "\n",
    "# Calculate training time\n",
    "logger.info(f\"Training took {(end - start) / 3600} hours.\")\n",
    "\n",
    "# Evaluation on validation set\n",
    "logger.info(\"*** Valid Evaluate ***\")\n",
    "valid_eval_output = trainer.evaluate()\n",
    "valid_perplexity = math.exp(valid_eval_output[\"eval_loss\"])\n",
    "valid_result = {\"valid_perplexity\": valid_perplexity}\n",
    "output_eval_file = os.path.join(training_args.output_dir, \"valid_eval_results_lm.txt\")\n",
    "\n",
    "with open(output_eval_file, \"w\") as writer:\n",
    "    logger.info(\"***** Valid Eval results *****\")\n",
    "    for key in sorted(valid_result.keys()):\n",
    "        logger.info(\"  %s = %s\", key, str(valid_result[key]))\n",
    "        writer.write(\"%s = %s\\n\" % (key, str(valid_result[key])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb749872",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Evaluation on test set\n",
    "training_args.do_eval = True\n",
    "data_args.eval_data_file = \"/home/cw862/arxiv/ml_full_dataset/test_ml_full.txt\"\n",
    "test_dataset = (\n",
    "    get_dataset(data_args, tokenizer=tokenizer, evaluate=True)\n",
    "    if training_args.do_eval\n",
    "    else None\n",
    ")\n",
    "trainer.eval_dataset = test_dataset\n",
    "\n",
    "logger.info(\"*** Test Evaluate ***\")\n",
    "test_eval_output = trainer.evaluate()\n",
    "test_perplexity = math.exp(test_eval_output[\"eval_loss\"])\n",
    "test_result = {\"test_perplexity\": test_perplexity}\n",
    "output_eval_file = os.path.join(training_args.output_dir, \"test_eval_results_lm.txt\")\n",
    "\n",
    "with open(output_eval_file, \"w\") as writer:\n",
    "    logger.info(\"***** Test Eval results *****\")\n",
    "    for key in sorted(test_result.keys()):\n",
    "        logger.info(\"  %s = %s\", key, str(test_result[key]))\n",
    "        writer.write(\"%s = %s\\n\" % (key, str(test_result[key])))\n",
    "\n",
    "\n",
    "# Evaluation on training set\n",
    "data_args.eval_data_file = \"/home/cw862/arxiv/AI_full_dataset/train_ai_all.txt\"\n",
    "test_dataset = (\n",
    "    get_dataset(data_args, tokenizer=tokenizer, evaluate=True)\n",
    "    if training_args.do_eval\n",
    "    else None\n",
    ")\n",
    "trainer.eval_dataset = test_dataset\n",
    "\n",
    "logger.info(\"*** Train Evaluate ***\")\n",
    "train_eval_output = trainer.evaluate()\n",
    "train_perplexity = math.exp(train_eval_output[\"eval_loss\"])\n",
    "train_result = {\"train_perplexity\": train_perplexity}\n",
    "output_eval_file = os.path.join(training_args.output_dir, \"train_eval_results_lm.txt\")\n",
    "\n",
    "with open(output_eval_file, \"w\") as writer:\n",
    "    logger.info(\"***** Train Eval results *****\")\n",
    "    for key in sorted(train_result.keys()):\n",
    "        logger.info(\"  %s = %s\", key, str(train_result[key]))\n",
    "        writer.write(\"%s = %s\\n\" % (key, str(train_result[key])))\n",
    "\n",
    "\n",
    "print(f\"Train loss: {train_eval_output['eval_loss']}\")\n",
    "print(f\"Valid loss: {valid_eval_output['eval_loss']}\")\n",
    "print(f\"Test loss: {test_eval_output['eval_loss']}\")\n",
    "print(f\"Train PPL: {train_perplexity}\")\n",
    "print(f\"Valid PPL: {valid_perplexity}\")\n",
    "print(f\"Test PPL: {test_perplexity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ae338e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8485af7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812c8dd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "448cf3c9",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
